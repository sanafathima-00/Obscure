# **Project Obscure**



## ğŸ•µï¸ Project Overview

**Project Obscure** is a stealthy, lightweight AI-powered desktop assistant that runs locally and interacts with the user through real-time voice-based conversations. It is screen-aware and privacy-friendly, built for smooth performance on low-resource systems.

---

## âœ¨ Features

- ğŸ§  Runs local LLM (Phi 3 mini via Ollama)
- ğŸ—£ï¸ Real-time speech-to-text input
- ğŸ—¨ï¸ Natural voice responses using text-to-speech
- ğŸ§¾ JSON-based short-term memory for contextual awareness
- ğŸ§° Prompt engineering for refined assistant behavior
- ğŸ–¥ï¸ Screen-aware through image or OCR hooks
- ğŸ’» <5% CPU usage on modest hardware (16GB RAM, i7 CPU)

---

## ğŸ› ï¸ Tech Stack

- **Language**: Python
- **LLM Runtime**: Ollama
- **Model**: Phi 3 mini (Lightweight LLM)
- **Voice Input**: `speech_recognition`
- **Voice Output**: `pyttsx3` / `edge-tts`
- **Memory**: Local JSON files
- **Screen Hook**: `pyautogui`, `pytesseract`

---

## ğŸš€ Installation and Setup

### Prerequisites
- Python 3.10+
- Ollama installed and running
- Phi model pulled via Ollama: `ollama run phi3 mini`

### Steps

1. **Clone the Repository**
```bash
git clone https://github.com/your-username/project-obscure.git
cd project-obscure
```

2. **Install Python Dependencies**
```bash
pip install -r requirements.txt
```

3. **Run the Assistant**
```bash
python main.py
```

4. Speak to your assistant â€” it responds with contextual awareness and continues the conversation naturally.

---

## ğŸ“ Project Structure

```
project-obscure/
â”œâ”€â”€ congig.py
â”œâ”€â”€ main.py
â”œâ”€â”€ memory.py
â”œâ”€â”€ speech.py
â””â”€â”€ vision.py
```

---

## ğŸ“¦ Dependencies

- `ollama`
- `requests`
- `speech_recognition`
- `pyttsx3` or `edge-tts`
- `pyaudio`
- `json`
- `pyautogui` 
- `pytesseract` 

---

## ğŸ”§ Customization

- Edit the prompt logic in `config.py`
- Tweak voice engine in `config.py`
- Extend memory logic via `memory.py`
- Add screen awareness using `vision.py`

---

## ğŸ Known Issues

- Initial load time may vary based on Ollama start
- Speech recognition depends on mic quality
- No GUI â€“ runs via terminal for now

---

## ğŸš§ Future Improvements

- GUI-based launcher for assistant
- OCR-based screen reading
- Task automation from spoken commands
- Plugin system for modular tools

---

## ğŸ“„ License

Licensed under the **MIT License**.

---

## ğŸ™Œ Acknowledgments

- [Ollama](https://ollama.com/) for local LLM hosting
- [Phi](https://huggingface.co/microsoft/phi-2) for an efficient model
- [SpeechRecognition](https://pypi.org/project/SpeechRecognition/) and [pyttsx3](https://pypi.org/project/pyttsx3/) for voice interaction
- The open-source community for enabling accessible AI
